{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Course 5: [Sequence Models](https://www.youtube.com/watch?v=_i3aqgKVNQI&index=1&list=PLkDaE6sCZn6F6wUI9tvS_Gw1vaFAx6rd6)\n",
    "\n",
    "Welcome to Sequence Models!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Week 1: Recurrent Neural Networks\n",
    "\n",
    "Learn about recurrent neural networks. This type of model has been proven to perform extremely well on temporal data. It has several variants including LSTMs, GRUs and Bidirectional RNNs, which you are going to learn about in this section.\n",
    "\n",
    "### Recurrent Neural Networks\n",
    "\n",
    "* Why sequence models (2 min)\n",
    "* Notation (9 min)\n",
    "* Recurrent Neural Network Model (16 min)\n",
    "* Backpropagation through time (6 min)\n",
    "* Different types of RNNs (9 min)\n",
    "* Language model and sequence generation (12 min)\n",
    "* Sampling novel sequences (8 min)\n",
    "* Vanishing gradients with RNNs (6 min)\n",
    "* Gated Recurrent Unit (GRU) (17 min)\n",
    "* Long Short Term Memory (LSTM) (9 min)\n",
    "* Bidirectional RNN (8 min)\n",
    "* Deep RNNs (5 min)\n",
    "\n",
    "## Practice Questions\n",
    "\n",
    "* Quiz: Recurrent Neural Networks (10 questions)\n",
    "\n",
    "## Programming assignments\n",
    "\n",
    "* Building a recurrent neural network - step by step (2h)\n",
    "* Dinosaur Island - Character-Level Language Modeling (1h)\n",
    "* Jazz improvisation with LSTM (1h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Week 2: Natural Language Processing & Word Embeddings\n",
    "\n",
    "Natural language processing with deep learning is an important combination. Using word vector representations and embedding layers you can train recurrent neural networks with outstanding performances in a wide variety of industries. Examples of applications are sentiment analysis, named entity recognition and machine translation.\n",
    "\n",
    "## Introduction to Word Embeddings\n",
    "\n",
    "* Word Representation (10 min)\n",
    "* Using word embeddings (9 min)\n",
    "* Properties of word embeddings (11 min)\n",
    "* Embedding matrix (5 min)\n",
    "\n",
    "## Learning Word Embeddings: Word2vec & GloVe\n",
    "\n",
    "* Learning word embeddings (10 min)\n",
    "* Word2Vec (12 min)\n",
    "* Negative Sampling (11 min)\n",
    "* GloVe word vectors (11 min)\n",
    "\n",
    "## Applications using Word Embeddings\n",
    "\n",
    "* Sentiment Classification (7 min)\n",
    "* Debiasing word embeddings (11 min)\n",
    "\n",
    "## Practice questions\n",
    "\n",
    "* Quiz: Natural Language Processing & Word Embeddings (10 questions)\n",
    "\n",
    "## Programming assignments\n",
    "\n",
    "* Operations on word vectors - Debiasing (1h)\n",
    "* Emojify (1h)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Week 3: Sequence models & Attention mechanism\n",
    "\n",
    "Sequence models can be augmented using an attention mechanism. This algorithm will help your model understand where it should focus its attention given a sequence of inputs. This week, you will also learn about speech recognition and how to deal with audio data.\n",
    "\n",
    "## Various sequence to sequence architectures\n",
    "\n",
    "* Basic Models (6 min)\n",
    "* Picking the most likely sentence (8 min)\n",
    "* Beam Search (11 min)\n",
    "* Refinements to Beam Search (11 min)\n",
    "* Error analysis in beam search (9 min)\n",
    "* Bleu Score (optional) (16 min)\n",
    "* Attention Model Intuition (9 min)\n",
    "* Attention Model (12 min)\n",
    "\n",
    "## Speech recognition - Audio data\n",
    "\n",
    "* Speech recognition (8 min)\n",
    "* Trigger Word Detection (5 min)\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "* Conclusion and thank you (2 min)\n",
    "\n",
    "## Practice questions\n",
    "\n",
    "* Quiz: Sequence models & Attention mechanism (10 questions)\n",
    "\n",
    "## Programming assignments\n",
    "\n",
    "* Neural Machine Translation with Attention (1h)\n",
    "* Trigger word detection (1h 30m)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
